{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Vanilla AutoEncoder\n",
    "* 이상 라벨 없이 reconstruction error에 기반해서 탐지"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "data = pd.read_csv(\"data/creditcard.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                Time            V1            V2            V3            V4  \\\ncount  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \nstd     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \nmin         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \nmax    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n\n                 V5            V6            V7            V8            V9  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \nstd    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \nmin   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \nmax    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n\n       ...           V21           V22           V23           V24  \\\ncount  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \nstd    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \nmin    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \nmax    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n\n                V25           V26           V27           V28         Amount  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \nmean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \nstd    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \nmin   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \nmax    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n\n               Class  \ncount  284807.000000  \nmean        0.001727  \nstd         0.041527  \nmin         0.000000  \n25%         0.000000  \n50%         0.000000  \n75%         0.000000  \nmax         1.000000  \n\n[8 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>284807.000000</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>...</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>284807.000000</td>\n      <td>284807.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>94813.859575</td>\n      <td>1.168375e-15</td>\n      <td>3.416908e-16</td>\n      <td>-1.379537e-15</td>\n      <td>2.074095e-15</td>\n      <td>9.604066e-16</td>\n      <td>1.487313e-15</td>\n      <td>-5.556467e-16</td>\n      <td>1.213481e-16</td>\n      <td>-2.406331e-15</td>\n      <td>...</td>\n      <td>1.654067e-16</td>\n      <td>-3.568593e-16</td>\n      <td>2.578648e-16</td>\n      <td>4.473266e-15</td>\n      <td>5.340915e-16</td>\n      <td>1.683437e-15</td>\n      <td>-3.660091e-16</td>\n      <td>-1.227390e-16</td>\n      <td>88.349619</td>\n      <td>0.001727</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>47488.145955</td>\n      <td>1.958696e+00</td>\n      <td>1.651309e+00</td>\n      <td>1.516255e+00</td>\n      <td>1.415869e+00</td>\n      <td>1.380247e+00</td>\n      <td>1.332271e+00</td>\n      <td>1.237094e+00</td>\n      <td>1.194353e+00</td>\n      <td>1.098632e+00</td>\n      <td>...</td>\n      <td>7.345240e-01</td>\n      <td>7.257016e-01</td>\n      <td>6.244603e-01</td>\n      <td>6.056471e-01</td>\n      <td>5.212781e-01</td>\n      <td>4.822270e-01</td>\n      <td>4.036325e-01</td>\n      <td>3.300833e-01</td>\n      <td>250.120109</td>\n      <td>0.041527</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-5.640751e+01</td>\n      <td>-7.271573e+01</td>\n      <td>-4.832559e+01</td>\n      <td>-5.683171e+00</td>\n      <td>-1.137433e+02</td>\n      <td>-2.616051e+01</td>\n      <td>-4.355724e+01</td>\n      <td>-7.321672e+01</td>\n      <td>-1.343407e+01</td>\n      <td>...</td>\n      <td>-3.483038e+01</td>\n      <td>-1.093314e+01</td>\n      <td>-4.480774e+01</td>\n      <td>-2.836627e+00</td>\n      <td>-1.029540e+01</td>\n      <td>-2.604551e+00</td>\n      <td>-2.256568e+01</td>\n      <td>-1.543008e+01</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>54201.500000</td>\n      <td>-9.203734e-01</td>\n      <td>-5.985499e-01</td>\n      <td>-8.903648e-01</td>\n      <td>-8.486401e-01</td>\n      <td>-6.915971e-01</td>\n      <td>-7.682956e-01</td>\n      <td>-5.540759e-01</td>\n      <td>-2.086297e-01</td>\n      <td>-6.430976e-01</td>\n      <td>...</td>\n      <td>-2.283949e-01</td>\n      <td>-5.423504e-01</td>\n      <td>-1.618463e-01</td>\n      <td>-3.545861e-01</td>\n      <td>-3.171451e-01</td>\n      <td>-3.269839e-01</td>\n      <td>-7.083953e-02</td>\n      <td>-5.295979e-02</td>\n      <td>5.600000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>84692.000000</td>\n      <td>1.810880e-02</td>\n      <td>6.548556e-02</td>\n      <td>1.798463e-01</td>\n      <td>-1.984653e-02</td>\n      <td>-5.433583e-02</td>\n      <td>-2.741871e-01</td>\n      <td>4.010308e-02</td>\n      <td>2.235804e-02</td>\n      <td>-5.142873e-02</td>\n      <td>...</td>\n      <td>-2.945017e-02</td>\n      <td>6.781943e-03</td>\n      <td>-1.119293e-02</td>\n      <td>4.097606e-02</td>\n      <td>1.659350e-02</td>\n      <td>-5.213911e-02</td>\n      <td>1.342146e-03</td>\n      <td>1.124383e-02</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>139320.500000</td>\n      <td>1.315642e+00</td>\n      <td>8.037239e-01</td>\n      <td>1.027196e+00</td>\n      <td>7.433413e-01</td>\n      <td>6.119264e-01</td>\n      <td>3.985649e-01</td>\n      <td>5.704361e-01</td>\n      <td>3.273459e-01</td>\n      <td>5.971390e-01</td>\n      <td>...</td>\n      <td>1.863772e-01</td>\n      <td>5.285536e-01</td>\n      <td>1.476421e-01</td>\n      <td>4.395266e-01</td>\n      <td>3.507156e-01</td>\n      <td>2.409522e-01</td>\n      <td>9.104512e-02</td>\n      <td>7.827995e-02</td>\n      <td>77.165000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>172792.000000</td>\n      <td>2.454930e+00</td>\n      <td>2.205773e+01</td>\n      <td>9.382558e+00</td>\n      <td>1.687534e+01</td>\n      <td>3.480167e+01</td>\n      <td>7.330163e+01</td>\n      <td>1.205895e+02</td>\n      <td>2.000721e+01</td>\n      <td>1.559499e+01</td>\n      <td>...</td>\n      <td>2.720284e+01</td>\n      <td>1.050309e+01</td>\n      <td>2.252841e+01</td>\n      <td>4.584549e+00</td>\n      <td>7.519589e+00</td>\n      <td>3.517346e+00</td>\n      <td>3.161220e+01</td>\n      <td>3.384781e+01</td>\n      <td>25691.160000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213236, 30)\n",
      "(71202, 30)\n"
     ]
    }
   ],
   "source": [
    "X_data = data.drop(\"Class\", axis=1)\n",
    "y_data = data[\"Class\"]\n",
    "\n",
    "#X_data.drop(\"Time\", axis=1, inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_data, y_data, stratify=y_data)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "\n",
    "zero_index = np.where(y_train==0)\n",
    "X_train = X_train[zero_index]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                480       \n",
      "=================================================================\n",
      "Total params: 945\n",
      "Trainable params: 945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input = Input(shape=(30, ))\n",
    "hidden = Dense(15, activation=\"relu\")(input)\n",
    "output = Dense(30, activation=\"linear\")(hidden)\n",
    "\n",
    "model = Model(inputs = input, outputs=output)\n",
    "model.compile(loss=\"MSE\", optimizer=\"Adam\", metrics=[\"mse\"])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6664/6664 [==============================] - 20s 3ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 2/50\n",
      "6664/6664 [==============================] - 20s 3ms/step - loss: 7.2517e-04 - mse: 7.2517e-04\n",
      "Epoch 3/50\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 6.4475e-04 - mse: 6.4475e-04\n",
      "Epoch 4/50\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 6.0784e-04 - mse: 6.0784e-04\n",
      "Epoch 5/50\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 5.0105e-04 - mse: 5.0105e-04\n",
      "Epoch 6/50\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 4.4979e-04 - mse: 4.4979e-04\n",
      "Epoch 7/50\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 4.4509e-04 - mse: 4.4509e-04\n",
      "Epoch 8/50\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 4.4303e-04 - mse: 4.4303e-04\n",
      "Epoch 9/50\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 4.4208e-04 - mse: 4.4208e-04\n",
      "Epoch 10/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.4149e-04 - mse: 4.4149e-04\n",
      "Epoch 11/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.4107e-04 - mse: 4.4107e-04\n",
      "Epoch 12/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.4079e-04 - mse: 4.4079e-04\n",
      "Epoch 13/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.4069e-04 - mse: 4.4069e-04\n",
      "Epoch 14/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.4046e-04 - mse: 4.4046e-04\n",
      "Epoch 15/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.4040e-04 - mse: 4.4040e-04\n",
      "Epoch 16/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.4009e-04 - mse: 4.4009e-04\n",
      "Epoch 17/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.4016e-04 - mse: 4.4016e-04\n",
      "Epoch 18/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.4011e-04 - mse: 4.4011e-04\n",
      "Epoch 19/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.3987e-04 - mse: 4.3987e-04\n",
      "Epoch 20/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3990e-04 - mse: 4.3990e-04\n",
      "Epoch 21/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.3987e-04 - mse: 4.3987e-04\n",
      "Epoch 22/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.3979e-04 - mse: 4.3979e-04\n",
      "Epoch 23/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.3981e-04 - mse: 4.3981e-04\n",
      "Epoch 24/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.3965e-04 - mse: 4.3965e-04\n",
      "Epoch 25/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3965e-04 - mse: 4.3965e-04\n",
      "Epoch 26/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.3963e-04 - mse: 4.3963e-04\n",
      "Epoch 27/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3953e-04 - mse: 4.3953e-04\n",
      "Epoch 28/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3959e-04 - mse: 4.3959e-04\n",
      "Epoch 29/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.3943e-04 - mse: 4.3943e-04\n",
      "Epoch 30/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.3943e-04 - mse: 4.3943e-04\n",
      "Epoch 31/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.3937e-04 - mse: 4.3937e-04\n",
      "Epoch 32/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3927e-04 - mse: 4.3927e-04\n",
      "Epoch 33/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.3935e-04 - mse: 4.3935e-04\n",
      "Epoch 34/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.3927e-04 - mse: 4.3927e-04\n",
      "Epoch 35/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.3920e-04 - mse: 4.3920e-04\n",
      "Epoch 36/50\n",
      "6664/6664 [==============================] - 17s 3ms/step - loss: 4.3924e-04 - mse: 4.3924e-04\n",
      "Epoch 37/50\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 4.3910e-04 - mse: 4.3910e-04\n",
      "Epoch 38/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3923e-04 - mse: 4.3923e-04\n",
      "Epoch 39/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3914e-04 - mse: 4.3914e-04\n",
      "Epoch 40/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3905e-04 - mse: 4.3905e-04\n",
      "Epoch 41/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3910e-04 - mse: 4.3910e-04\n",
      "Epoch 42/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3906e-04 - mse: 4.3906e-04\n",
      "Epoch 43/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3904e-04 - mse: 4.3904e-04\n",
      "Epoch 44/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3902e-04 - mse: 4.3902e-04\n",
      "Epoch 45/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3891e-04 - mse: 4.3891e-04\n",
      "Epoch 46/50\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 4.3896e-04 - mse: 4.3896e-04\n",
      "Epoch 47/50\n",
      "6664/6664 [==============================] - 18s 3ms/step - loss: 4.3892e-04 - mse: 4.3892e-04\n",
      "Epoch 48/50\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 4.3886e-04 - mse: 4.3886e-04\n",
      "Epoch 49/50\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 4.3883e-04 - mse: 4.3883e-04\n",
      "Epoch 50/50\n",
      "6664/6664 [==============================] - 19s 3ms/step - loss: 4.3890e-04 - mse: 4.3890e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1f2886e9460>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, X_train,\n",
    "          epochs=50,\n",
    "          batch_size=32,\n",
    "          verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(71202, 30)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_valid)\n",
    "pred.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    7.120200e+04\n",
      "mean     5.087525e+12\n",
      "std      2.032243e+13\n",
      "min      1.410600e+05\n",
      "25%      3.747116e+11\n",
      "50%      1.658349e+12\n",
      "75%      5.068743e+12\n",
      "max      1.124496e+15\n",
      "dtype: float64\n",
      "0    6.638324e+12\n",
      "1    1.624131e+11\n",
      "2    1.315858e+10\n",
      "3    5.053166e+12\n",
      "4    3.506914e+12\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import EmpiricalCovariance\n",
    "\n",
    "# 공분산행렬 계산\n",
    "emp_cov = EmpiricalCovariance().fit(pred)\n",
    "\n",
    "# 마할라노비스 거리\n",
    "outlier_score = emp_cov.mahalanobis(X_valid)\n",
    "outlier_score = pd.Series(outlier_score)\n",
    "\n",
    "print(outlier_score.describe())\n",
    "print(outlier_score.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "outlier_score_np = outlier_score.to_numpy()\n",
    "outlier_score_np = np.sort(outlier_score_np)\n",
    "outlier_score_np = MinMaxScaler().fit_transform(outlier_score_np.reshape(-1, 1))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(outlier_score_np)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9984410550265442\n",
      "precision : 1.0\n",
      "recall : 0.0975609756097561\n",
      "f1 : 0.17777777777777776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "outlier_score_np = outlier_score.to_numpy()\n",
    "outlier_score_np = MinMaxScaler().fit_transform(outlier_score_np.reshape(-1, 1))\n",
    "# print(outlier_score_np)\n",
    "# plt.plot(outlier_score_np)\n",
    "# plt.show()\n",
    "\n",
    "threshold = 0.8\n",
    "pred_label = [1 if i > threshold else 0 for i in outlier_score_np ]\n",
    "\n",
    "\n",
    "print(\"accuracy :\", accuracy_score(y_true=y_valid, y_pred=pred_label))  # imbalance data이기 때문에 별 의미 없음\n",
    "print(\"precision :\", precision_score(y_true=y_valid, y_pred=pred_label))  # anomaly detection에선 정밀도가 더 중요!\n",
    "print(\"recall :\", recall_score(y_true=y_valid, y_pred=pred_label))\n",
    "print(\"f1 :\", f1_score(y_true=y_valid, y_pred=pred_label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5843621399176955\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "outlier_score_np = outlier_score.to_numpy()\n",
    "outlier_score_np = MinMaxScaler().fit_transform(outlier_score_np.reshape(-1, 1))\n",
    "# print(outlier_score_np)\n",
    "# plt.plot(outlier_score_np)\n",
    "# plt.show()\n",
    "\n",
    "maxvalue = 0\n",
    "maxindex = 0\n",
    "for t in range(100):\n",
    "\n",
    "    threshold = t / 100.\n",
    "    pred_label = [1 if i > threshold else 0 for i in outlier_score_np ]\n",
    "\n",
    "\n",
    "    # print(\"accuracy :\", accuracy_score(y_true=y_valid, y_pred=pred_label))  # imbalance data이기 때문에 별 의미 없음\n",
    "    # print(\"precision :\", precision_score(y_true=y_valid, y_pred=pred_label))  # anomaly detection에선 정밀도가 더 중요!\n",
    "    # print(\"recall :\", recall_score(y_true=y_valid, y_pred=pred_label))\n",
    "    # print(\"f1 :\", f1_score(y_true=y_valid, y_pred=pred_label))\n",
    "\n",
    "    if f1_score(y_true=y_valid, y_pred=pred_label) > maxvalue:\n",
    "        maxvalue = f1_score(y_true=y_valid, y_pred=pred_label)\n",
    "        maxindex = t\n",
    "\n",
    "print(maxvalue)\n",
    "print(maxindex)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}